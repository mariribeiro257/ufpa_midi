{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c3ca68",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --quiet mido numpy scipy matplotlib soundfile\n",
    "# NOTE: the above command installs the packages used in this notebook.\n",
    "# If you already have them in your environment you can skip rerunning this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8f619b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports used throughout the notebook\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# `spectrogram` is used for the multi-FFT time-frequency view\n",
    "from scipy.signal import spectrogram\n",
    "# `soundfile` is used to write WAV files (optional but convenient)\n",
    "import soundfile as sf\n",
    "# `mido` is used to construct and parse simple MIDI files for the polyphonic example\n",
    "import mido\n",
    "import os\n",
    "\n",
    "# Make plots wider by default for readability\n",
    "plt.rcParams['figure.figsize'] = (10, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f78ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilities: conversions and plotting helpers\n",
    "# - `midi_note_to_freq` converts MIDI note numbers to frequency in Hz\n",
    "# - `adsr_envelope` provides a very simple envelope to avoid clicks and shape notes\n",
    "# - plotting helpers create consistent, labeled visualizations\n",
    "\n",
    "def midi_note_to_freq(m):\n",
    "    # MIDI note to frequency (A4 = MIDI 69 = 440 Hz) using equal-tempered tuning.\n",
    "    return 440.0 * 2 ** ((m - 69) / 12.0)\n",
    "\n",
    "def adsr_envelope(length, sr, attack=0.01, release=0.05):\n",
    "    # Very small ADSR-like envelope: linear attack then sustain (1.0) then linear release.\n",
    "    # Parameters: `length` in seconds, `sr` sample rate, `attack`/`release` in seconds.\n",
    "    n = int(length * sr)\n",
    "    env = np.ones(n)\n",
    "    a = int(attack * sr)\n",
    "    r = int(release * sr)\n",
    "    if a > 0:\n",
    "        env[:a] = np.linspace(0, 1, a)\n",
    "    if r > 0:\n",
    "        env[-r:] = np.linspace(1, 0, r)\n",
    "    return env\n",
    "\n",
    "def plot_waveform(signal, sr, title='Waveform', tmin=None, tmax=None):\n",
    "    # Plot amplitude vs time; optionally focus on a time window with tmin/tmax.\n",
    "    times = np.arange(len(signal)) / sr\n",
    "    if tmin is not None and tmax is not None:\n",
    "        mask = (times >= tmin) & (times <= tmax)\n",
    "        times = times[mask]\n",
    "        sig = signal[mask]\n",
    "    else:\n",
    "        sig = signal\n",
    "    plt.figure()\n",
    "    plt.plot(times, sig, linewidth=0.7)\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_single_fft(signal, sr, title='Single FFT (magnitude)', n_fft=None, freq_limit=5000):\n",
    "    # Compute a single (global) FFT to show the overall frequency content of `signal`.\n",
    "    # We apply a Hann window to reduce leakage before taking the FFT.\n",
    "    x = signal.astype(float)\n",
    "    if n_fft is None:\n",
    "        n_fft = len(x)\n",
    "    X = np.fft.rfft(x * np.hanning(len(x)), n=n_fft)\n",
    "    freqs = np.fft.rfftfreq(n_fft, 1.0 / sr)\n",
    "    mag = np.abs(X)\n",
    "    # For clarity limit the frequency axis to `freq_limit` Hz (fundamentals/harmonics)\n",
    "    idx = freqs <= freq_limit\n",
    "    plt.figure()\n",
    "    plt.plot(freqs[idx], 20 * np.log10(mag[idx] + 1e-12))\n",
    "    plt.xlabel('Frequency (Hz)')\n",
    "    plt.ylabel('Magnitude (dB)')\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_spectrogram(signal, sr, title='Spectrogram', nperseg=1024, noverlap=None, freq_limit=8000):\n",
    "    # Spectrogram: many short-time FFTs to show frequency content over time.\n",
    "    if noverlap is None:\n",
    "        noverlap = nperseg // 2\n",
    "    f, t, Sxx = spectrogram(signal, fs=sr, nperseg=nperseg, noverlap=noverlap, scaling='spectrum')\n",
    "    # Restrict frequency axis to focus on fundamentals and low harmonics\n",
    "    fmask = f <= freq_limit\n",
    "    plt.figure()\n",
    "    plt.pcolormesh(t, f[fmask], 10 * np.log10(Sxx[fmask, :] + 1e-12), shading='gouraud')\n",
    "    plt.ylabel('Frequency [Hz]')\n",
    "    plt.xlabel('Time [sec]')\n",
    "    plt.title(title)\n",
    "    plt.colorbar(label='Power (dB)')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0bcefd",
   "metadata": {},
   "source": [
    "## Part 1 — Monophonic synthesis (no MIDI)\n",
    "This section synthesizes a short melody using single sine tones played sequentially (monophonic).\n",
    "We will show:\n",
    "- The waveform (time-domain),\n",
    "- A single global FFT (one FFT over the whole signal) to show frequency content,\n",
    "- A spectrogram (many FFTs over short windows) to show how frequencies evolve in time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62252d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monophonic sequence: list of (midi_note, duration_seconds)\n",
    "# We use MIDI note numbers for convenience; they are converted to Hz when synthesizing.\n",
    "sr = 22050  # sample rate (Hz)\n",
    "mono_notes = [(64, 0.5), (66, 0.5), (68, 0.5), (69, 1.0), (68, 0.5), (66, 0.5), (64, 1.0)]\n",
    "\n",
    "def synth_mono_sequence(notes, sr=22050):\n",
    "    # Synthesize each note as a sine wave, apply a short ADSR envelope and concatenate.\n",
    "    parts = []\n",
    "    for note, dur in notes:\n",
    "        freq = midi_note_to_freq(note)\n",
    "        t = np.linspace(0, dur, int(sr * dur), endpoint=False)\n",
    "        # Pure sine tone (monophonic), amplitude chosen to avoid clipping when saved\n",
    "        tone = 0.6 * np.sin(2 * np.pi * freq * t)\n",
    "        # Apply a small attack and release to avoid clicks\n",
    "        env = adsr_envelope(dur, sr)\n",
    "        parts.append(tone * env)\n",
    "    return np.concatenate(parts)\n",
    "\n",
    "# Generate the monophonic signal and save it to `outputs/mono_synthesis.wav`\n",
    "mono_signal = synth_mono_sequence(mono_notes, sr=sr)\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "sf_path_mono = 'outputs/mono_synthesis.wav'\n",
    "sf.write(sf_path_mono, mono_signal, sr)\n",
    "\n",
    "# Visualizations: waveform, single FFT and spectrogram\n",
    "plot_waveform(mono_signal, sr, title='Monophonic waveform (whole)')\n",
    "plot_single_fft(mono_signal, sr, title='Monophonic — single FFT')\n",
    "plot_spectrogram(mono_signal, sr, title='Monophonic — spectrogram', nperseg=1024, freq_limit=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fea991d",
   "metadata": {},
   "source": [
    "## Part 2 — Polyphonic via MIDI (programmatic)\n",
    "We will create a tiny MIDI file with overlapping notes and then synthesize audio by additive synthesis.\n",
    "The MIDI is only used for note timing and velocities; the audio is synthesized here with sine waves\n",
    "so the example is self-contained (no external soundfont required)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5fa470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple MIDI file programmatically (single track, fixed tempo)\n",
    "# This demonstrates how to encode start/end times for overlapping notes (polyphony).\n",
    "mid = mido.MidiFile()\n",
    "track = mido.MidiTrack()\n",
    "mid.tracks.append(track)\n",
    "# Tempo: 120 BPM (microseconds per beat)\n",
    "tempo = mido.bpm2tempo(120)\n",
    "track.append(mido.MetaMessage('set_tempo', tempo=tempo, time=0))\n",
    "ticks_per_beat = mid.ticks_per_beat\n",
    "\n",
    "# Helper: convert seconds to MIDI ticks using the current tempo and ticks_per_beat\n",
    "def seconds_to_ticks(seconds, tempo, ticks_per_beat):\n",
    "    # tempo is microseconds per beat; convert to seconds per beat first\n",
    "    us_per_beat = tempo\n",
    "    seconds_per_beat = us_per_beat / 1e6\n",
    "    beats = seconds / seconds_per_beat\n",
    "    return int(round(beats * ticks_per_beat))\n",
    "\n",
    "# Define a short progression with intentionally overlapping notes (start times/durations)\n",
    "events = [  # (note, start_s, duration_s, velocity)\n",
    "    (60, 0.0, 1.0, 100),\n",
    "    (64, 0.25, 1.0, 100),\n",
    "    (67, 0.5, 1.0, 100),\n",
    "    (72, 1.0, 1.5, 100),\n",
    "    (76, 1.25, 1.0, 100),\n",
    "    (79, 1.5, 1.0, 100)\n",
    "]\n",
    "\n",
    "# Convert events to note_on/note_off messages with absolute tick times, then to delta times\n",
    "msgs = []\n",
    "for note, start, dur, vel in events:\n",
    "    t_on = seconds_to_ticks(start, tempo, ticks_per_beat)\n",
    "    t_off = seconds_to_ticks(start + dur, tempo, ticks_per_beat)\n",
    "    msgs.append((t_on, mido.Message('note_on', note=note, velocity=vel, time=0)))\n",
    "    msgs.append((t_off, mido.Message('note_off', note=note, velocity=0, time=0)))\n",
    "# Sort by absolute tick time\n",
    "msgs.sort(key=lambda x: x[0])\n",
    "# Convert to delta-times and append to the track\n",
    "last_tick = 0\n",
    "for tick, message in msgs:\n",
    "    delta = tick - last_tick\n",
    "    message.time = delta\n",
    "    track.append(message)\n",
    "    last_tick = tick\n",
    "\n",
    "midi_path = 'outputs/example_polyphony.mid'\n",
    "mid.save(midi_path)\n",
    "print('Saved MIDI to', midi_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef38be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the MIDI file and extract note events as (start_s, end_s, note, vel)\n",
    "def parse_midi_to_events(midi_path):\n",
    "    # We assume a single track and a (nearly) constant tempo set earlier in the file.\n",
    "    mf = mido.MidiFile(midi_path)\n",
    "    ticks_per_beat = mf.ticks_per_beat\n",
    "    tempo = 500000  # default microseconds per beat if none set\n",
    "    # Walk messages accumulating absolute tick times and collect matched note on/off pairs\n",
    "    abs_ticks = 0\n",
    "    note_states = {}  # note -> (start_tick, velocity)\n",
    "    events = []\n",
    "    for msg in mf:  # iterates through messages in time order with msg.time in ticks\n",
    "        abs_ticks += msg.time\n",
    "        if msg.type == 'set_tempo':\n",
    "            tempo = msg.tempo\n",
    "        if msg.type == 'note_on' and msg.velocity > 0:\n",
    "            note_states[msg.note] = (abs_ticks, msg.velocity)\n",
    "        elif (msg.type == 'note_off') or (msg.type == 'note_on' and msg.velocity == 0):\n",
    "            if msg.note in note_states:\n",
    "                start_tick, vel = note_states.pop(msg.note)\n",
    "                events.append((start_tick, abs_ticks, msg.note, vel))\n",
    "    # Convert ticks to seconds using the tempo in effect (simple approach assuming constant tempo)\n",
    "    def ticks_to_seconds(ticks, tempo, ticks_per_beat):\n",
    "        return (ticks * tempo) / (ticks_per_beat * 1e6)\n",
    "    events_sec = [(ticks_to_seconds(s, tempo, ticks_per_beat), ticks_to_seconds(e, tempo, ticks_per_beat), n, v) for (s, e, n, v) in events]\n",
    "    return events_sec\n",
    "\n",
    "events_sec = parse_midi_to_events(midi_path)\n",
    "print('Parsed events (start_s, end_s, note, vel):')\n",
    "for ev in events_sec:\n",
    "    print(ev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17a8336",
   "metadata": {},
   "outputs": [],
   "source": [
    "def synth_from_midi_events(events, sr=22050, max_duration=None):\n",
    "    # events: list of (start_s, end_s, note, vel)\n",
    "    # Synthesize each note as a sine wave and add to an output buffer at the proper offsets.\n",
    "    if max_duration is None:\n",
    "        max_duration = max(e[1] for e in events)\n",
    "    n_samples = int(np.ceil(max_duration * sr))\n",
    "    out = np.zeros(n_samples, dtype=float)\n",
    "    for start_s, end_s, note, vel in events:\n",
    "        start_i = int(np.floor(start_s * sr))\n",
    "        end_i = int(np.floor(end_s * sr))\n",
    "        dur = (end_i - start_i) / sr\n",
    "        if dur <= 0:\n",
    "            continue\n",
    "        t = np.linspace(0, dur, end_i - start_i, endpoint=False)\n",
    "        freq = midi_note_to_freq(note)\n",
    "        # amplitude scaled by velocity and a modest gain to avoid excessive clipping when summing\n",
    "        amp = (vel / 127.0) * 0.4\n",
    "        tone = amp * np.sin(2 * np.pi * freq * t)\n",
    "        env = adsr_envelope(dur, sr)\n",
    "        tone = tone * env\n",
    "        out[start_i:start_i + len(tone)] += tone\n",
    "    # simple normalization to -1..1 to prevent clipping when saving\n",
    "    maxv = np.max(np.abs(out))\n",
    "    if maxv > 0:\n",
    "        out = out / (maxv + 1e-12) * 0.9\n",
    "    return out\n",
    "\n",
    "poly_signal = synth_from_midi_events(events_sec, sr=sr)\n",
    "sf_path_poly = 'outputs/poly_from_midi.wav'\n",
    "sf.write(sf_path_poly, poly_signal, sr)\n",
    "print('Saved synthesized polyphonic WAV to', sf_path_poly)\n",
    "\n",
    "# Plots for polyphonic output: waveform, single FFT, and spectrogram\n",
    "plot_waveform(poly_signal, sr, title='Polyphonic (MIDI-driven) waveform (whole)')\n",
    "plot_single_fft(poly_signal, sr, title='Polyphonic — single FFT', freq_limit=5000)\n",
    "plot_spectrogram(poly_signal, sr, title='Polyphonic — spectrogram', nperseg=1024, freq_limit=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40153586",
   "metadata": {},
   "source": [
    "## Comparison notes (visual)\n",
    "- The single FFT gives a snapshot of frequency content (global or selected window). For monophonic sound the FFT will show strong peaks at the played note frequencies. For polyphony the FFT will show multiple simultaneous peaks (chords).\n",
    "- The spectrogram shows how frequencies change over time. In the monophonic spectrogram you'll see a single ridge moving from note to note. In the polyphonic spectrogram you'll see multiple ridges overlapping when notes sound together.\n",
    "\n",
    "We intentionally keep the spectral analysis simple (one global FFT and a standard spectrogram) to emphasize the evolving frequency content rather than low-level spectral details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef86a7a6",
   "metadata": {},
   "source": [
    "### Next steps\n",
    "- Run each cell in order inside a Jupyter environment.\n",
    "- Optionally change `events` or `mono_notes` to experiment with different melodies and timings.\n",
    "- If you want a more realistic MIDI-based timbre, we can connect to a SoundFont-based synth (e.g., `fluidsynth`) or use `pretty_midi` with sampled instruments."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
